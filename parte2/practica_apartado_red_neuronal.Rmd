---
title: "practica_apartado_red_neuronal"
author: "Antonio Galián Gálvez"
date: "2024-12-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Seleccioamos el directorio actual como directorio de trabajo
# Si estamos compilando no lo hacemos para que no de error la compilación
if (interactive()) {
  setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}

# Cargamos las librerías necesarias
library(summarytools)
library(randomForest)
library(keras)
library(magrittr)
library(MLmetrics)

# Seleccionamos la semilla aleatoria para todo el cuaderno
set.seed(12345)
```

```{r}
# Leemos el dataset preprocesado
mydf <- read.csv("sampled_preprocesed.csv", header = TRUE, sep = ",")

# Pasamos las variables correspondientes a factor
mydf$Protocol <- as.factor(mydf$Protocol)
mydf$Fwd.PSH.Flags <- as.factor(mydf$Fwd.PSH.Flags)
mydf$FIN.Flag.Count <- as.factor(mydf$FIN.Flag.Count)
mydf$SYN.Flag.Count <- as.factor(mydf$SYN.Flag.Count)
mydf$PSH.Flag.Count <- as.factor(mydf$PSH.Flag.Count)
mydf$ACK.Flag.Count <- as.factor(mydf$ACK.Flag.Count)
mydf$URG.Flag.Count <- as.factor(mydf$URG.Flag.Count)
mydf$CWE.Flag.Count <- as.factor(mydf$CWE.Flag.Count)
mydf$Class <- as.factor(mydf$Class)

# Nos aseguramos de que la clase positiva sea "Keylogger" asignando como clase de referencia a "Benign"
mydf$Class <- relevel(mydf$Class, ref = "Benign")

#Nos quedamos con las columnas numéricas
# mydf.numeric <- mydf[,which(sapply(mydf, is.numeric))]
# mydf.numeric <- as.data.frame(scale(mydf.numeric))
mydf.numeric <- as.data.frame(scale(sapply(mydf, as.numeric)))

# Añadimos la columna a predecir
mydf.numeric$Class <- mydf$Class
```

```{r}
# Definimos el conjunto de test
test_indices <- sample(1:nrow(mydf.numeric), as.integer(0.3 * nrow(mydf.numeric)))
test <- mydf.numeric[test_indices, ]

# Definimos el conjunto de train
train_indices <- setdiff(1:nrow(mydf.numeric), test_indices)
train <- mydf.numeric[train_indices, ]
```

Para llevar a cabo el proceso de validación cruzada, dividiremos el conjunto de train en n pliegues. El número elegido será n=5 pliegues.

```{r}
# Definimos el número de pliegues
n <- 5

# Generamos un vector de igual longitud que el numero de filas de train, asociando cada valor a un pliegue
folds_indexes <- sample(rep(1:n, length.out = nrow(train)))

# Obtenemos los pliegues aplicando la secuencia anterior a los datos de train
folds <- split(train, folds_indexes)
```



```{r}
library(doParallel)


# Set up parallel backend to use multiple processors
cl <- makeCluster(detectCores() - 1) # Leave one core free
registerDoParallel(cl)

# Definimos los valores de mtry, ntree y nodesize que vamos a probar
values.nneurons1 <- c(2**4, 2**5, 1024)
values.nneurons2 <- c(0, 2**4, 2**5, 1024)
values.epochs <- c(50, 100, 150, 200)

v <- expand.grid(values.nneurons1, values.nneurons2, values.epochs)
colnames(v) <- c("Units Layer 1", "Units Layer 2", "Epocas")

f1.score.fold <- rep(0, length(folds))
accuracy.fold <- rep(0, length(folds))

inicio <- Sys.time()

# Entrenamos el modelo de bagging en paralelo
mean_accuracy_sd <- foreach(i = 1:nrow(v), .combine = rbind, .packages = c("keras", "MLmetrics")) %dopar% {
  test_fold <- rep(0, length(folds))

  # Creamos la red neuronal con los parámetros de los vectores
  if (v[i, 2] == 0) {
    modnn <- keras_model_sequential() %>%
      layer_dense(units = v[i, 1], activation = "relu", input_shape = c(ncol(mydf.numeric)-1)) %>%
      layer_dropout(rate = 0.5) %>%
      layer_dense(units = 2, activation = "softmax")
  } else {
    modnn <- keras_model_sequential() %>%
      layer_dense(units = v[i, 1], activation = "relu", input_shape = c(ncol(mydf.numeric)-1)) %>%
      layer_dropout(rate = 0.5) %>%
      layer_dense(units = v[i, 2], activation = "relu") %>%
      layer_dropout(rate = 0.5) %>%
      layer_dense(units = 2, activation = "softmax")
  }

  # Compilamos la red neuronal
  modnn %>% compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_adam(),
    metrics = c("accuracy")
  )

  for (k in seq(1:length(folds))) {
    # Juntamos todos los folds menos el k
    data <- do.call(rbind, folds[-k])

    # Definimos las variables de entrada y de salida del conjunto de entrenamiento
    x_train <- as.matrix(data[, -ncol(data)])
    y_train <- as.numeric(data$Class == "Keylogger")

    y_train <- to_categorical(y_train, 2)
    # Entrenamos la red con el conjunto de entrenamiento
    modnn %>% fit(x_train, y_train, epochs = v[i, 3], verbose = 1)

    # Creamos las variables de entrada y salida para el conjunto de test
    x_test <- as.matrix(folds[[k]][, -ncol(folds[[k]])])
    y_test <- as.numeric(folds[[k]]$Class == "Keylogger")

    # Predecimos la probabilidad de que la variable de salida sea "Keylogger"
    yhat.modnn <- predict(modnn, x_test)
    y_pred_class <- ifelse(yhat.modnn[, 1] > 0.5, 0, 1)

    # Guardamos la accuracy obtenida comparando las predicciones y los outputs reales del pliegue k
    # f1.score.fold[k] <- F1_Score(y_pred = y_pred_class, y_true = y_test, positive = "1")
    accuracy.fold[k] <- Accuracy(y_pred = y_pred_class, y_true = y_test)
    F1_Score(y_pred = y_pred_class, y_true = y_test, positive = "1")
  }

  # Hacemos la media de los accuracy de todos los pliegues
  # mean_f1.score_fold <- mean(f1.score.fold)
  mean_accuracy_fold <- mean(accuracy.fold)


  # sd_f1.score_fold <- sd(f1.score.fold)/sqrt(length(folds))
  sd_accuracy_fold <- sd(accuracy.fold) / sqrt(length(folds))
  c(mean_accuracy_fold, sd_accuracy_fold)
}

final <- Sys.time()

train_time <- as.numeric(difftime(final, inicio, units = "secs"))

# Stop the cluster
stopCluster(cl)
```

```{r}
mean_accuracy_sd

max_index <- which.max(mean_accuracy_sd[,1])
max_accuracy <- max(mean_accuracy_sd[,1])
range_max_accuracy <- max_accuracy - mean_accuracy_sd[max_index,2]

mean_accuracy_sd_w_max <- mean_accuracy_sd[-max_index,]


for (i in seq(1:length(mean_accuracy_sd_w_max[,1]))) {
  
  if (mean_accuracy_sd_w_max[i,1] + mean_accuracy_sd_w_max[i,2] >= range_max_accuracy) {
    
      print(v[i,])
      print(mean_accuracy_sd_w_max[i,1])
    
  }
  
}

#plot(mean_accuracy_sd[, 1] / max(mean_accuracy_sd[, 1]), main = "Accuracy relativo")

# plot(mean_accuracy_sd[,3]/max(mean_accuracy_sd[,3]),main="Accuracy relativo")


plot(mean_accuracy_sd_w_max[, 1] + mean_accuracy_sd_w_max[,2], main = "Accuracy absoluto")
abline(h=range_max_accuracy,col=2)

# plot(mean_accuracy_sd[,3],main="Accuracy absoluto")
```

Pasamos el tiempo de segundos a horas, minutos y segundos
```{r}
horas <- as.integer(train_time %/% 3600)
resto <- as.integer(train_time %% 3600)
minutos <- as.integer(resto %/% 60)
segundos_finales <- as.integer(resto %% 60)

resultado <- sprintf("El entrenamiento ha tardado %d horas, %d minutos y %d segundos", horas, minutos, segundos_finales)
print(resultado)
```

#################################################
#Lo siguiente es lo que habia antes
#################################################
#################################################

"""
```{r,eval=FALSE}
library(doParallel)

# Set up parallel backend to use multiple processors
cl <- makeCluster(detectCores() - 1) # Leave one core free
registerDoParallel(cl)

# Definimos los valores de mtry, ntree y nodesize que vamos a probar
values.units.layer.1 <- 2**c(4, 5, 6)
values.dropout.rate.1 <- c(0.3, 0.5)
values.units.layer.2 <- 2**c(4, 5, 6)
values.dropout.rate.2 <- c(0.3, 0.5)
values.epochs <- c(50, 100, 150, 200)

# Creamos una matriz con todas las combinaciones posibles de los valores de mtry, ntree y nodesize
v <- expand.grid(values.units.layer.1, values.dropout.rate.1, values.units.layer.2, values.dropout.rate.2, values.epochs)

colnames(v) <- c("Units Layer 1", "Dropout Rate 1", "Units Layer 2", "Dropout Rate 2", "Épocas")

f1.score.fold <- rep(0, length(folds))
accuracy.fold <- rep(0, length(folds))

inicio <- Sys.time()

# Entrenamos el modelo de bagging en paralelo
mean_accuracy_sd <- foreach(i = 1:nrow(v), .combine = rbind, .packages = c("keras", "MLmetrics")) %dopar% {
  test_fold <- rep(0, length(folds))
  for (k in seq(1:length(folds))) {
    # Juntamos todos los folds menos el k
    data <- do.call(rbind, folds[-k])

    # Definimos las variables de entrada y de salida del conjunto de entrenamiento
    x_train <- as.matrix(sapply(data[, -ncol(data)], as.numeric))
    y_train <- as.numeric(data$Class == "Keylogger")

    # Creamos la red neuronal
    modnn <- keras_model_sequential() %>%
      layer_dense(units = v[i, 1], activation = "relu", input_shape = ncol(x_train)) %>%
      layer_dropout(rate = v[i, 2]) %>%
      layer_dense(units = v[i, 3], activation = "relu") %>%
      layer_dropout(rate = v[i, 4]) %>%
      layer_dense(units = 1, activation = "sigmoid")

    # La compilamos
    modnn %>% compile(
      loss = "binary_crossentropy",
      optimizer = optimizer_adam(),
      metrics = c("accuracy")
    )

    # Entrenamos la red con el conjunto de entrenamiento
    modnn %>% fit(x_train, y_train, epochs = v[i, 5], verbose = 0)


    # Creamos las variables de entrada y salida para el conjunto de test
    x_test <- as.matrix(sapply(folds[[k]][, -ncol(folds[[k]])], as.numeric))
    y_test <- as.numeric(folds[[k]]$Class == "Keylogger")

    # Predecimos la probabilidad de que la variable de salida sea "Keylogger"
    yhat.modnn <- predict(modnn, x_test)
    y_pred_class <- ifelse(yhat.modnn[, 1] > 0.5, 1, 0)

    # Guardamos la accuracy obtenida comparando las predicciones y los outputs reales del pliegue k
    # f1.score.fold[k] <- F1_Score(y_pred = y_pred_class, y_true = y_test, positive = "1")
    accuracy.fold[k] <- Accuracy(y_pred = y_pred_class, y_true = y_test)
  }

  # Hacemos la media de los accuracy de todos los pliegues
  # mean_f1.score_fold <- mean(f1.score.fold)
  mean_accuracy_fold <- mean(accuracy.fold)


  # sd_f1.score_fold <- sd(f1.score.fold)/sqrt(length(folds))
  sd_accuracy_fold <- sd(accuracy.fold) / sqrt(length(folds))
  c(mean_accuracy_fold, sd_accuracy_fold)
}

final <- Sys.time()

train_time <- as.numeric(difftime(final, inicio, units = "secs"))

# Stop the cluster
stopCluster(cl)
```