---
title: "practica_apartado_red_neuronal"
author: "Antonio Galián Gálvez"
date: "2024-12-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Seleccioamos el directorio actual como directorio de trabajo
# Si estamos compilando no lo hacemos para que no de error la compilación
if (interactive()) {
  setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}

# Cargamos las librerías necesarias
library(summarytools)
library(randomForest)
library(keras)
library(magrittr)
library(MLmetrics)
library(doParallel)

# Seleccionamos la semilla aleatoria para todo el cuaderno
set.seed(12345)
```

```{r}
# Leemos el dataset preprocesado
mydf <- read.csv("sampled_preprocesed.csv", header = TRUE, sep = ",")

# Pasamos las variables correspondientes a factor
mydf$Protocol <- as.factor(mydf$Protocol)
mydf$Fwd.PSH.Flags <- as.factor(mydf$Fwd.PSH.Flags)
mydf$FIN.Flag.Count <- as.factor(mydf$FIN.Flag.Count)
mydf$SYN.Flag.Count <- as.factor(mydf$SYN.Flag.Count)
mydf$PSH.Flag.Count <- as.factor(mydf$PSH.Flag.Count)
mydf$ACK.Flag.Count <- as.factor(mydf$ACK.Flag.Count)
mydf$URG.Flag.Count <- as.factor(mydf$URG.Flag.Count)
mydf$CWE.Flag.Count <- as.factor(mydf$CWE.Flag.Count)
mydf$Class <- as.factor(mydf$Class)

# Nos aseguramos de que la clase positiva sea "Keylogger" asignando como clase de referencia a "Benign"
mydf$Class <- relevel(mydf$Class, ref = "Benign")

#Nos quedamos con las columnas numéricas, y a estas columnas les aplicamos un escalado para mejorar las predicciones
mydf.numeric <- as.data.frame(scale(sapply(mydf, as.numeric)))

# Añadimos la columna a predecir
mydf.numeric$Class <- mydf$Class
```

```{r}
# Definimos el conjunto de test
test_indices <- sample(1:nrow(mydf.numeric), as.integer(0.3 * nrow(mydf.numeric)))
test <- mydf.numeric[test_indices, ]

# Definimos el conjunto de train
train_indices <- setdiff(1:nrow(mydf.numeric), test_indices)
train <- mydf.numeric[train_indices, ]
```

```{r}
# Definimos el número de pliegues
n <- 5

# Generamos un vector de igual longitud que el numero de filas de train, asociando cada valor a un pliegue
folds_indexes <- sample(rep(1:n, length.out = nrow(train)))

# Obtenemos los pliegues aplicando la secuencia anterior a los datos de train
folds <- split(train, folds_indexes)
```



```{r}
# Creamos un cluster para realizar los cálculos en paralelo
cl <- makeCluster(detectCores() - 1) # Dejamos un núcleo libre

# Registramos el cluster
registerDoParallel(cl)

# Definimos los valores de nodos, dropout y epocas que vamos a probar
values.nneurons1 <- c(16, 32, 64)
values.nneurons2 <- c(0, 16, 32, 64)
values.dropout.rate <- c(0.1,0.3,0.5)
values.epochs <- c(50, 100, 200)

# Creamos una matriz con todas las combinaciones posibles de los valores de nodos, dropout y epocas
v <- expand.grid(values.nneurons1, values.nneurons2, values.dropout.rate, values.epochs)
colnames(v) <- c("Units Layer 1", "Units Layer 2", "Dropout Rate", "Epocas")

# Creamos una variable de tiempo para ver cuánto tarda en ejecutarse
inicio <- Sys.time()

# Creamos una variable para guardar el F1-Score
f1score.folds <- rep(0, length(folds))
accuracy.folds <- rep(0, length(folds))

# Entrenamos el modelo de bagging en paralelo
crossvalidation.results <- foreach(i = 1:nrow(v), .combine = rbind, .packages = c("keras", "MLmetrics")) %dopar% {
  
  
  # Configuramos los pesos para las distintas clases según la proporción en la que aparecen
  class_weights <- list(
      "0" = 1, # Peso para la clase "Benign"
      "1" = prop.table(table(train$Class))[[1]] / prop.table(table(train$Class))[[2]]  # Peso para la clase "keylogger". Dividimos la proporción de "Benign" entre la de "Keylogger", en el conjunto de entrenamiento
    )

  # Creamos la red neuronal con los parámetros de los vectores
  if (v[i, 2] == 0) {
    modnn <- keras_model_sequential() %>%
      layer_dense(units = v[i, 1], activation = "relu", input_shape = c(ncol(mydf.numeric)-1)) %>%
      layer_dropout(rate = v[i, 3]) %>%
      layer_dense(units = 2, activation = "softmax")
  } else {
    modnn <- keras_model_sequential() %>%
      layer_dense(units = v[i, 1], activation = "relu", input_shape = c(ncol(mydf.numeric)-1)) %>%
      layer_dropout(rate = v[i, 3]) %>%
      layer_dense(units = v[i, 2], activation = "relu") %>%
      layer_dropout(rate = v[i, 3]) %>%
      layer_dense(units = 2, activation = "softmax")
  }

  # Compilamos la red neuronal
  modnn %>% compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_adam(),
    metrics = c("accuracy")
  )

  for (k in seq(1:length(folds))) {
    
    # Juntamos todos los folds menos el k
    data <- do.call(rbind, folds[-k])

    # Definimos las variables de entrada y de salida del conjunto de entrenamiento
    x.train <- as.matrix(data[, -ncol(data)])
    y.train <- as.numeric(data$Class == "Keylogger")

    #Pasamos la columna de salida de entrenamiento a dos columnas, donde cada una representa una clase
    y.train <- to_categorical(y.train, 2)
    
    # Entrenamos la red con el conjunto de entrenamiento
    modnn %>% fit(x.train, y.train, epochs = v[i, 3], verbose = 0, class_weight = class_weights)

    # Definimos las variables de entrada y salida para el conjunto de test
    x.test <- as.matrix(folds[[k]][, -ncol(folds[[k]])])
    y.test <- as.numeric(folds[[k]]$Class == "Keylogger")

    # Predecimos la probabilidad de que la variable de salida sea "Keylogger"
    # Predecimos con el pliegue que hemos dejado fuera del entrenamiento
    y.pred <- predict(modnn, x.test)
    
    # Definimos para la segunda columna de salida que tenga la etiqueta "Keylogger"
    # si su probabilidad es mayor que 0.5
    y.pred.class <- ifelse(y.pred[, 2] > 0.5, 1, 0)

    # Guardamos el F1-Score obtenido comparando las predicciones y los datos reales del pliegue k
    f1score.folds[k] <- F1_Score(y_pred = y.pred.class, y_true = y.test, positive = "1")
    accuracy.folds[k] <- Accuracy(y_pred = y.pred.class, y_true = y.test)
  }

  # Hacemos la media de los F1-Score de todos los pliegues
  mean.f1score <- mean(f1score.folds)
  se.f1score <- sd(f1score.folds) / sqrt(length(folds))

  # Hacemos una media del Accuracy de todos los pliegues
  mean.accuracy <- mean(accuracy.folds)
  se.accuracy <- sd(accuracy.folds) / sqrt(length(folds))

  # Devolvemos los resultados
  c(mean.f1score, se.f1score, mean.accuracy, se.accuracy)
}

# Guardamos el tiempo final
final <- Sys.time()

# Calculamos el tiempo de entrenamiento
train.time <- as.numeric(difftime(final, inicio, units = "secs"))
train.time <- sprintf("%02.0f:%02.0f:%02.0f", train.time %/% 3600, (train.time %% 3600) %/% 60, train.time %% 60)

# Guaradmos el tiempo de entrenamiento en un DataFrame
train.time.df <- data.frame(time_bagging = train.time)
train.time.df$time_bagging_sec <- as.numeric(difftime(final, inicio, units = "secs"))

# Guardamos el tiempo de entrenamiento en un archivo
write.csv(train.time.df, "train_time_neuralnetwork.csv", row.names = FALSE)

# Creamos un DataFrame con los resultados de la validación cruzada
crossvalidation.results <- as.data.frame(crossvalidation.results)
colnames(crossvalidation.results) <- c("mean_f1score", "se_f1score", "mean_accuracy", "se_accuracy")
crossvalidation.results <- cbind(v, crossvalidation.results)

# Guardamos los resultados de la validación cruzada en un archivo
write.csv(crossvalidation.results, "crossvalidation_neuralnetwork.csv", row.names = FALSE)

crossvalidation.results
```

```{r}
mean_accuracy_sd

max_index <- which.max(mean_accuracy_sd[,1])
max_accuracy <- max(mean_accuracy_sd[,1])
range_max_accuracy <- max_accuracy - mean_accuracy_sd[max_index,2]

mean_accuracy_sd_w_max <- mean_accuracy_sd[-max_index,]


for (i in seq(1:length(mean_accuracy_sd_w_max[,1]))) {
  
  if (mean_accuracy_sd_w_max[i,1] + mean_accuracy_sd_w_max[i,2] >= range_max_accuracy) {
    
      print(v[i,])
      print(mean_accuracy_sd_w_max[i,1])
    
  }
  
}

#plot(mean_accuracy_sd[, 1] / max(mean_accuracy_sd[, 1]), main = "Accuracy relativo")

# plot(mean_accuracy_sd[,3]/max(mean_accuracy_sd[,3]),main="Accuracy relativo")


plot(mean_accuracy_sd_w_max[, 1] + mean_accuracy_sd_w_max[,2], main = "Accuracy absoluto")
abline(h=range_max_accuracy,col=2)

# plot(mean_accuracy_sd[,3],main="Accuracy absoluto")
```

Pasamos el tiempo de segundos a horas, minutos y segundos
```{r}
horas <- as.integer(train_time %/% 3600)
resto <- as.integer(train_time %% 3600)
minutos <- as.integer(resto %/% 60)
segundos_finales <- as.integer(resto %% 60)

resultado <- sprintf("El entrenamiento ha tardado %d horas, %d minutos y %d segundos", horas, minutos, segundos_finales)
print(resultado)
```

#################################################
#Lo siguiente es lo que habia antes
#################################################
#################################################

"""
```{r,eval=FALSE}
library(doParallel)

# Set up parallel backend to use multiple processors
cl <- makeCluster(detectCores() - 1) # Leave one core free
registerDoParallel(cl)

# Definimos los valores de mtry, ntree y nodesize que vamos a probar
values.units.layer.1 <- 2**c(4, 5, 6)
values.dropout.rate.1 <- c(0.3, 0.5)
values.units.layer.2 <- 2**c(4, 5, 6)
values.dropout.rate.2 <- c(0.3, 0.5)
values.epochs <- c(50, 100, 150, 200)

# Creamos una matriz con todas las combinaciones posibles de los valores de mtry, ntree y nodesize
v <- expand.grid(values.units.layer.1, values.dropout.rate.1, values.units.layer.2, values.dropout.rate.2, values.epochs)

colnames(v) <- c("Units Layer 1", "Dropout Rate 1", "Units Layer 2", "Dropout Rate 2", "Épocas")

f1.score.fold <- rep(0, length(folds))
accuracy.fold <- rep(0, length(folds))

inicio <- Sys.time()

# Entrenamos el modelo de bagging en paralelo
mean_accuracy_sd <- foreach(i = 1:nrow(v), .combine = rbind, .packages = c("keras", "MLmetrics")) %dopar% {
  test_fold <- rep(0, length(folds))
  for (k in seq(1:length(folds))) {
    # Juntamos todos los folds menos el k
    data <- do.call(rbind, folds[-k])

    # Definimos las variables de entrada y de salida del conjunto de entrenamiento
    x_train <- as.matrix(sapply(data[, -ncol(data)], as.numeric))
    y_train <- as.numeric(data$Class == "Keylogger")

    # Creamos la red neuronal
    modnn <- keras_model_sequential() %>%
      layer_dense(units = v[i, 1], activation = "relu", input_shape = ncol(x_train)) %>%
      layer_dropout(rate = v[i, 2]) %>%
      layer_dense(units = v[i, 3], activation = "relu") %>%
      layer_dropout(rate = v[i, 4]) %>%
      layer_dense(units = 1, activation = "sigmoid")

    # La compilamos
    modnn %>% compile(
      loss = "binary_crossentropy",
      optimizer = optimizer_adam(),
      metrics = c("accuracy")
    )

    # Entrenamos la red con el conjunto de entrenamiento
    modnn %>% fit(x_train, y_train, epochs = v[i, 5], verbose = 0)


    # Creamos las variables de entrada y salida para el conjunto de test
    x_test <- as.matrix(sapply(folds[[k]][, -ncol(folds[[k]])], as.numeric))
    y_test <- as.numeric(folds[[k]]$Class == "Keylogger")

    # Predecimos la probabilidad de que la variable de salida sea "Keylogger"
    yhat.modnn <- predict(modnn, x_test)
    y_pred_class <- ifelse(yhat.modnn[, 1] > 0.5, 1, 0)

    # Guardamos la accuracy obtenida comparando las predicciones y los outputs reales del pliegue k
    # f1.score.fold[k] <- F1_Score(y_pred = y_pred_class, y_true = y_test, positive = "1")
    accuracy.fold[k] <- Accuracy(y_pred = y_pred_class, y_true = y_test)
  }

  # Hacemos la media de los accuracy de todos los pliegues
  # mean_f1.score_fold <- mean(f1.score.fold)
  mean_accuracy_fold <- mean(accuracy.fold)


  # sd_f1.score_fold <- sd(f1.score.fold)/sqrt(length(folds))
  sd_accuracy_fold <- sd(accuracy.fold) / sqrt(length(folds))
  c(mean_accuracy_fold, sd_accuracy_fold)
}

final <- Sys.time()

train_time <- as.numeric(difftime(final, inicio, units = "secs"))

# Stop the cluster
stopCluster(cl)
```