---
title: "practica_apartado_red_neuronal"
author: "Antonio Galián Gálvez"
date: "2024-12-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, results = "hide", message = FALSE, warning = FALSE}
# Seleccioamos el directorio actual como directorio de trabajo
# Si estamos compilando no lo hacemos para que no de error la compilación
if (interactive()) {
  setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}

# Cargamos las librerías necesarias
library(summarytools)
library(randomForest)
library(keras)
library(magrittr)
library(doParallel)
library(MLmetrics)
library(reticulate)

# Seleccionamos la semilla aleatoria para todo el cuaderno
set.seed(12345)
```

```{r}
# Leemos el dataset preprocesado
mydf <- read.csv("sampled.csv", header = TRUE, sep = ",")

# Pasamos las variables correspondientes a factor
mydf$Protocol <- as.factor(mydf$Protocol)
mydf$Fwd.PSH.Flags <- as.factor(mydf$Fwd.PSH.Flags)
mydf$FIN.Flag.Count <- as.factor(mydf$FIN.Flag.Count)
mydf$SYN.Flag.Count <- as.factor(mydf$SYN.Flag.Count)
mydf$PSH.Flag.Count <- as.factor(mydf$PSH.Flag.Count)
mydf$ACK.Flag.Count <- as.factor(mydf$ACK.Flag.Count)
mydf$URG.Flag.Count <- as.factor(mydf$URG.Flag.Count)
mydf$CWE.Flag.Count <- as.factor(mydf$CWE.Flag.Count)
mydf$Class <- as.factor(mydf$Class)

# Nos aseguramos de que la clase positiva sea "Keylogger" asignando como clase de referencia a "Benign"
mydf$Class <- relevel(mydf$Class, ref = "Benign")
```

```{r}
# Escogemos los datos numéricos
mydf.numeric <- mydf[, sapply(mydf, is.numeric)]

# Escalamos los datos numéricos
mydf.numeric.scaled <- scale(mydf.numeric)

# Introducimos los datos escalados en el dataset
mydf[, sapply(mydf, is.numeric)] <- mydf.numeric.scaled
```

```{r}
# Dividimos el dataset en train y test
train_index <- sample(1:nrow(mydf), nrow(mydf) * 0.8)
train <- mydf[train_index, ]
test <- mydf[-train_index, ]
```

```{r}
# Definimos el número de pliegues
n <- 5

# Generamos un vector de igual longitud que el numero de filas de train, asociando cada valor a un pliegue
folds_indexes <- sample(rep(1:n, length.out = nrow(train)))
```

```{r}
# Convertimos todas las variables a numéricas y las escalamos
mydf.numeric <- as.data.frame(scale(sapply(mydf, as.numeric)))
mydf.numeric$Class <- mydf$Class

# Seleccionamos el conjunto de test y entrenamiento con los índices creados en el apartado de bagging
train <- mydf.numeric[train_index, ]
test <- mydf.numeric[-train_index, ]

# Obtenemos los pliegues aplicando los índices usados
folds <- split(train, folds_indexes)
```

```{r}
# Definimos los valores de nodos, dropout y epocas que vamos a probar
values.nneurons1 <- c(16, 32)
values.nneurons2 <- c(0, 16, 32)
values.dropout.rate <- c(0.1, 0.5)
values.epochs <- c(50, 100)

# Creamos una matriz con todas las combinaciones posibles de los valores de nodos, dropout y epocas
v <- expand.grid(values.nneurons1, values.nneurons2, values.dropout.rate, values.epochs)
colnames(v) <- c("Units Layer 1", "Units Layer 2", "Dropout Rate", "Epocas")
```

```{r}
# Cargamos los resultados de la validación cruzada
crossvalidation.results <- read.table("crossvalidation_neuralnetwork.csv", header = TRUE, sep = ",")

# Seleccionamos los resultados para el F1-Score
f1score.mean <- crossvalidation.results$mean_f1score
f1score.se <- crossvalidation.results$se_f1score

# Representamos los resultados en un plot para verlos mejor
plot(
  f1score.mean,
  xlab = "Combinación de hiperparámetros",
  ylab = "Media de F1-Score",
  main = "Media de F1-Score en función de los hiperparámetros",
)
grid(
  nx = NULL,
  ny = NULL,
  col = "lightgray",
  lty = "dotted",
  lwd = par("lwd"),
  equilogs = TRUE
)
arrows(1:length(f1score.mean), f1score.mean - f1score.se, 1:length(f1score.mean), f1score.mean + f1score.se, angle = 90, code = 3, length = 0.1)

# Seleccionamos el hiperparámetro que ha obtenido el mejor F1-Score
f1score.max.arg <- which.max(f1score.mean)
f1score.max.threshold <- f1score.mean[f1score.max.arg] - f1score.se[f1score.max.arg]
f1score.values <- f1score.mean + f1score.se
f1score.valids.args <- which(f1score.values > f1score.max.threshold)

# Vemos los parámetros que podemos seleccionar y escogemos a mano el más simple con mejor resultado
print(crossvalidation.results[f1score.valids.args, ])

# Vemos el conjunto de hiperparámetros elegido
v.op <- v[13, ]
v.op <- as.vector(unlist(v.op))
names(v.op) <- c("Units Layer 1", "Units Layer 2", "Dropout Rate", "Epocas")
v.op
```

```{r}
# Cargamos la red neuronal de Python y lo pasamos a R
py_run_string("import keras")
py_run_string("model = keras.models.load_model('model.keras')")
modnn <- py$model

# Realizamos las predicciones con el conjunto de test
test.numeric <- as.matrix(as.numeric(test$Class))
test.numeric <- ifelse(test.numeric == 1, 0, 1)
test.numeric <- to_categorical(test.numeric, 2)
y.pred <- predict(modnn, as.matrix(test[, -ncol(test)]), verbose = 0)

# Obtenemos las clases
y.pred.class <- ifelse(y.pred[, 2] > 0.5, 1, 0)

# Calculamos el F1-Score y la precisión
f1score <- F1_Score(y_pred = y.pred.class, y_true = as.numeric(test$Class == "Keylogger"), positive = 1)
accuracy <- Accuracy(y_pred = y.pred.class, y_true = as.numeric(test$Class == "Keylogger"))
print(paste("F1-Score: ", f1score, sep = ""))
print(paste("Accuracy: ", accuracy, sep = ""))

# Realizamos una matriz de confusión
confusion_matrix <- table(predicted = y.pred.class, real = as.numeric(test$Class == "Keylogger"))
print(round(addmargins(prop.table(confusion_matrix)), 4) * 100)
```