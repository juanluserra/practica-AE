---
title: "practica_apartado_bagging"
author: "Antonio Galián Gálvez"
date: "2024-12-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Seleccioamos el directorio actual como directorio de trabajo
# Si estamos compilando no lo hacemos para que no de error la compilación
if (interactive()) {
  setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}

# Cargamos las librerías necesarias
library(summarytools)
library(randomForest)
library(keras)
library(magrittr)
library(MLmetrics)
library(tictoc)

# Seleccionamos la semilla aleatoria para todo el cuaderno
set.seed(12345)
```

```{r}
# Leemos el dataset preprocesado
mydf <- read.csv("sampled_preprocesed.csv", header = TRUE, sep = ",")

# Pasamos las variables correspondientes a factor
mydf$Protocol <- as.factor(mydf$Protocol)
mydf$Fwd.PSH.Flags <- as.factor(mydf$Fwd.PSH.Flags)
mydf$FIN.Flag.Count <- as.factor(mydf$FIN.Flag.Count)
mydf$SYN.Flag.Count <- as.factor(mydf$SYN.Flag.Count)
mydf$PSH.Flag.Count <- as.factor(mydf$PSH.Flag.Count)
mydf$ACK.Flag.Count <- as.factor(mydf$ACK.Flag.Count)
mydf$URG.Flag.Count <- as.factor(mydf$URG.Flag.Count)
mydf$CWE.Flag.Count <- as.factor(mydf$CWE.Flag.Count)
mydf$Class <- as.factor(mydf$Class)

# Nos aseguramos de que la clase positiva sea "Keylogger" asignando como clase de referencia a "Benign"
mydf$Class <- relevel(mydf$Class, ref = "Benign")
```

```{r}
# Definimos el conjunto de test
test_indices <- sample(1:nrow(mydf), as.integer(0.3 * nrow(mydf)))
test <- mydf[test_indices, ]

# Definimos el conjunto de train
train_indices <- setdiff(1:nrow(mydf), test_indices)
train <- mydf[train_indices, ]
```

Para llevar a cabo el proceso de validación cruzada, dividiremos el conjunto de train en n pliegues. El número elegido será n=5 pliegues.

```{r}
# Definimos el número de pliegues
n <- 5

# Generamos un vector de igual longitud que el numero de filas de train, asociando cada valor a un pliegue
folds_indexes <- sample(rep(1:n, length.out = nrow(train)))

# Obtenemos los pliegues aplicando la secuencia anterior a los datos de train
folds <- split(train, folds_indexes)
```


```{r}
library(doParallel)

# Set up parallel backend to use multiple processors
cl <- makeCluster(detectCores() - 1) # Leave one core free
registerDoParallel(cl)

# Definimos los valores de mtry, ntree y nodesize que vamos a probar
values.mtry.op <- as.integer(sqrt(ncol(mydf)))
values.mtry <- c(values.mtry.op - 1, values.mtry.op, values.mtry.op + 1)
values.ntree <- c(300, 350,400,450,500,550,600,650, 700)
values.nsizes <- c(1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500)

# Creamos una matriz con todas las combinaciones posibles de los valores de mtry, ntree y nodesize
v <- expand.grid(values.mtry, values.ntree, values.nsizes)

colnames(v) <- c("mtry", "ntree", "nodesize")

f1.score.fold <- rep(0, length(folds))
accuracy.fold <- rep(0, length(folds))

inicio <- Sys.time()

# Entrenamos el modelo de bagging en paralelo
mean_accuracy_sd <- foreach(i = 1:nrow(v), .combine = rbind, .packages = c("randomForest", "MLmetrics")) %dopar% {
  test_fold <- rep(0, length(folds))
  for (k in seq(1:length(folds))) {
    # Juntamos todos los folds menos el k
    data <- do.call(rbind, folds[-k])

    # Creamos el modelo de bagging
    bag <- randomForest(Class ~ .,
      data = data,
      mtry = v[i, 1], ntree = v[i, 2], maxnodes = v[i, 3]
    )

    # Predecimos con el pliegue que hemos dejado fuera del entrenamiento
    yhat.bag <- predict(bag, newdata = folds[[k]])

    # Guardamos la accuracy obtenida comparando las predicciones y los outputs reales del pliegue k
    f1.score.fold[k] <- F1_Score(y_pred = yhat.bag, y_true = folds[[k]]$Class, positive = "Keylogger")
    accuracy.fold[k] <- Accuracy(y_pred = yhat.bag, y_true = folds[[k]]$Class)
  }

  # Hacemos la media de los accuracy de todos los pliegues
  mean_f1.score_fold <- mean(f1.score.fold)
  mean_accuracy_fold <- mean(accuracy.fold)

  
  sd_f1.score_fold <- sd(f1.score.fold)/sqrt(length(folds))
  sd_accuracy_fold <- sd(accuracy.fold)/sqrt(length(folds))
  c(mean_f1.score_fold, sd_f1.score_fold, mean_accuracy_fold, sd_accuracy_fold)
}

final <- Sys.time()

train_time <- as.numeric(difftime(final, inicio, units = "secs"))

# Stop the cluster
stopCluster(cl)
```


```{r}

mean_accuracy_sd



plot(mean_accuracy_sd[,1]/max(mean_accuracy_sd[,1]), main="F1_Score y Accuracy relativos (Accuracy en rojo)")

points(mean_accuracy_sd[,3]/max(mean_accuracy_sd[,3]),col=2)


plot(mean_accuracy_sd[,1], main="F1_Score absoluto")

plot(mean_accuracy_sd[,3],main="Accuracy absoluto")




```

```{r}
write.csv(mean_accuracy_sd, file = "mean_sd.csv")

write.csv(v, file = "vectors.csv",row.names = TRUE)

```

Pasamos el tiempo de segundos a horas, minutos y segundos
```{r}

horas <- as.integer(train_time %/% 3600)      
resto <- as.integer(train_time %% 3600)        
minutos <- as.integer(resto %/% 60)            
segundos_finales <- as.integer(resto %% 60)        

resultado <- sprintf("El entrenamiento ha tardado %d horas, %d minutos y %2d segundos", horas, minutos, segundos_finales)
print(resultado)

```


