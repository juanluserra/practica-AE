---
title: "Práctica AE"
author: "Antonio Galián Gálvez"
date: "2024-10-28"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(encoding = "UTF-8")
```

# 0. Cargamos los datos y eliminamos la columna train
```{r}
# Cargamos los datos con separador de tabulador
datos <- read.delim("prostate.data.txt", header = TRUE, sep = "\t")

# Eliminamos la columna train
datos <- datos[, -ncol(datos)]
```

# 1. Exploración de datos
```{r}
# Vemos las variables que hay
ncol(datos)

# Eliminamos la columna id
datos <- datos[, -1]

# Comprobamos si hay NA
sum(is.na(datos))

# Comprobamos si las variables estan estandarizadas
summary(datos)

dim(datos)
names(datos)
str(datos)
summary(datos)
```

- Hay 10 variables, 9 si quitamos el id del paciente
- Las variables son numéricas
- La variable correspondiente al identificador del paciente es la primera columna
- No hay valores nulos
- Las variables no están ni normalizadas ni estandarizadas
- Hay variables que están en escala logarítmica ya que algunas variables tienen valores negativos a pesar de estar definidas estrictamente positivas, como la concentración en ng/m

# 2

```{r}

attach(datos)

datos$svi <- as.factor(datos$svi)

datos$gleason <- as.factor(datos$gleason)

datos$age <- as.factor(datos$age)



str(datos)
```
# 3
```{r}
a <- datos[datos$gleason == "7", ]

b <- a[a$svi == "0", ]

num.a <- dim(a)[1]

num.b <- dim(b)[1]

porcentaje.ab <- num.b / (num.a) * 100

c <- datos[datos$svi == "0", ]

d <- c[c$gleason == "7", ]

num.c <- dim(c)[1]

num.d <- dim(d)[1]

porcentaje.cd <- num.d / (num.c) * 100


tabla <- table(svi, gleason)

addmargins(prop.table(tabla,1),2)*100
addmargins(prop.table(tabla,2),1)*100

```

# 4

```{r}

recta <- lm(lpsa ~ lcavol)

summary(recta)

plot(lcavol, lpsa, main='lpsa vs lcavol')
abline(recta, col = "red")

confint(recta, level = 0.95)

r1 <- residuals(recta)
sqrt(sum(r1^2) / (dim(datos)[1] - 2)) # RSE


```

# 5

```{r}

library(corrplot)

datos

num_cols <- which(sapply(datos, is.numeric))

corrplot(cor(datos[,num_cols]),type="upper",tl.cex=0.5)

datos.num <- datos[,c(-3,-7,-8)]

rectaMul <- lm(lpsa ~ .,data=datos.num)

summary(rectaMul)

```
#6

```{r}

library(glmnet)


x <- model.matrix(lpsa~.,datos.num)[,-1] #variables numericas

x

y <- datos.num$lpsa #variable de salida

set.seed(1)

train <- sample(1:nrow(x), nrow(x)/2) #filas de entrenamiento

test <- (-train)


y.test <- y[test]

malla <- 10^seq(10,-2,length=100) #mallado de lambdas


# Ridge



malla.ridge.train <- glmnet(x[train,],y[train],alpha=0,lambda=malla) # regresion ridge sin CV con conjunto de entrenamiento

plot(malla.ridge.train,xvar="lambda" ) # plot de betas vs log(lambda)



cv.out.ridge.train <- cv.glmnet(x[train,],y[train],alpha=0)  # regresion ridge con CV con conjunto de entrenamiento

bestlam.ridge.train<-cv.out.ridge.train$lambda.min  #lambda que minmiza el MSE

bestlam.ridge.train

ridge.train<-glmnet(x[train,],y[train],alpha=0, lambda=bestlam.ridge.train) #regresion ridge con CV con mejor lambda en conjunto de entrenamiento

coef(ridge.train)[,1]

rectaMul.train <- glmnet(x[train,],y[train],alpha=0, lambda=0)  # regresion multiple con datos de entrenamiento

coef(rectaMul.train)[,1]

#el intercept es mayor en ridge
# beta de lcp mayor en ridge
# los demas betas son menores en ridge

plot(cv.out.ridge.train)  #MSE vs log(lambda)

ridge.pred <- predict(ridge.train,newx=x[test,]) # predicion de 'ridge.train' en conjunto de testeo



mean((ridge.pred-y.test)^2) #MSE estimado de Ridge


rectaMul.pred <- predict(rectaMul.train,newx=x[test,])

mean((rectaMul.pred-y.test)^2) #MSE estimado de rectaMul

# El MSE de la regresion multiple de Ridge es menor que la de rectaMul

##############################################################################
#Lasso
##############################################################################


malla.lasso.train <- glmnet(x[train,],y[train],alpha=1,lambda=malla) # regresion lasso sin CV con conjunto de entrenamiento

plot(malla.lasso.train,xvar="lambda" ) # plot de betas vs log(lambda)



cv.out.lasso.train <- cv.glmnet(x[train,],y[train],alpha=1)  # regresion lasso con CV con conjunto de entrenamiento

bestlam.lasso.train<-cv.out.lasso.train$lambda.min  #lambda que minmiza el MSE

bestlam.lasso.train

lasso.train<-glmnet(x[train,],y[train],alpha=1, lambda=bestlam.lasso.train) #regresion lasso con CV con mejor lambda en conjunto de entrenamiento

coef(lasso.train)[,1]


#el intercept es mayor en lasso
# beta de lcp mayor en lasso
# los demas betas son menores en lasso

plot(cv.out.lasso.train)  #MSE vs log(lambda)

lasso.pred <- predict(lasso.train,newx=x[test,]) # predicion de 'lasso.train' en conjunto de testeo



mean((lasso.pred-y.test)^2) #MSE estimado de lasso


rectaMul.pred <- predict(rectaMul.train,newx=x[test,])

mean((rectaMul.pred-y.test)^2) #MSE estimado de rectaMul

# El MSE de la regresion multiple de lasso es menor que la de rectaMul

```
#7

```{r}

library(MASS)

lda=lda(svi~ lcavol+lcp+lpsa)  

lda

lda.pred=predict(lda)


tabla.confusion.lda <- table(lda.pred$class,svi)  # tabla de confusion

#hay pocos valores no diagonales en comparacion con la diagonal, buen modelo

(tabla.confusion.lda[1,2] + tabla.confusion.lda[2,1])/sum(tabla.confusion.lda) * 100 # 11.34% de datos mal clasificados
 
```
#8

```{r}

lr<-glm(svi~ lcavol+lcp+lpsa,family=binomial)

lr.probs<-predict(lr,type="response")

lr.pred<-rep(0,97)
 
lr.pred[lr.probs > .5]=1

table(lr.pred)

table(svi)

# Hay 3 datos mal clasificados

predict(lr,newdata = data.frame(lcavol = 2.8269,lcp=1.843, lpsa=3.285),type="response")

# Prob de 0.77. bien


```

#9

```{r}

datos.num$svi <- as.numeric(datos$svi)

variables_pca <- datos.num[, c("lcavol", "lweight", "lbph", "lcp", "svi")]

variables_pca

pr.out <- prcomp(variables_pca, scale = TRUE)

pr.out

summary(pr.out)

biplot(pr.out, scale = 0)  #biplot



```

