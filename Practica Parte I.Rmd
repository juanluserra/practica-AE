---
title: "Práctica AE"
author: "Antonio Galián Gálvez"
date: "2024-10-28"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(encoding = "UTF-8")
```

```{r}
library(gplots)
```

# 0. Cargamos los datos y eliminamos la columna train
```{r}
# Cargamos los datos con separador de tabulador
datos <- read.delim("prostate.data.txt", header = TRUE, sep = "\t")

# Eliminamos la columna train
datos <- datos[, -ncol(datos)]
```

# 1. Exploración de datos
```{r}
# Vemos las variables que hay
ncol(datos)

# Eliminamos la columna id
datos <- datos[, -1]

# Comprobamos si hay NA
sum(is.na(datos))

# Comprobamos si las variables estan estandarizadas
summary(datos)

dim(datos)
names(datos)
str(datos)
summary(datos)
```

- Hay 10 variables, 9 si quitamos el id del paciente
- Las variables son numéricas
- La variable correspondiente al identificador del paciente es la primera columna
- No hay valores nulos
- Las variables no están ni normalizadas ni estandarizadas
- Hay variables que están en escala logarítmica ya que algunas variables tienen valores negativos a pesar de estar definidas estrictamente positivas, como la concentración en ng/m

# 2. Análisis de variable categóricas
```{r}
# Convertimos las variables en factores
datos$svi <- as.factor(datos$svi)
datos$gleason <- as.factor(datos$gleason)
datos$age <- as.factor(datos$age)

# Comprobamos que las variables son categóricas
str(datos)
```

# 3. Análisis de frecuencias

- **¿Qué porcentaje de pacientes con la puntuación de Gleason igual a 7, presenta índice igual svi igual a 0?**
```{r}
# Seleccionamos los pacientes con la puntuación de Gleason igual a 7 y los que tienen svi igual a 0 dentro de estos
datos.gleason7 <- datos[datos$gleason == "7", ]
datos.gleason7.svi0 <- datos.gleason7[datos.gleason7$svi == "0", ]

# Vemos los pacientes que hay en datos.gleason_7_0 y en datos
patients.gleason7.svi0 <- nrow(datos.gleason7.svi0)
patients <- nrow(datos)

# Dividimos la cantidad de pacientes filtrados entre el total
porcentaje <- patients.gleason7.svi0 / patients * 100
porcentaje
```
Vemos que el porcentaje es del 38.14433%.

- **¿Qué porcentaje de pacientes con índice svi igual a 0 tiene la puntuación de Gleason igual a 7?**
```{r}
# Seleccionamos los individuos con svi igual a 0 y con gleason igual a 7 dentro de estos
datos.svi0 <- datos[datos$svi == "0", ]
datos.svi0.gleason7 <- datos.svi0[datos.svi0$gleason == "7", ]

# Hacemos el porcentaje
porcentaje <- nrow(datos.svi0.gleason7) / nrow(datos.svi0) * 100
porcentaje
```
Vemos que el porcentaje es del 48.68421%.

- **Estas dos variables, ¿son independientes?**
```{r}
# Hacemos un attach al dataset
attach(datos)

# Creamos una tabla con las dos variables
tabla <- table(svi, gleason)

# Creamos tablas de probabilidad por fila y por columna
addmargins(prop.table(tabla, 1), 2) * 100
addmargins(prop.table(tabla, 2), 1) * 100

# Realizamos un gráfico de la tabla para visualizar mejor la Independencia
heatmap.2(
    prop.table(tabla),
    xlab = "Gleason", ylab = "SVI",
    density.info = "none",
    col = blues9,
    trace = "none",
)
```

# 4

```{r}

recta <- lm(lpsa ~ lcavol)

summary(recta)

plot(lcavol, lpsa, main='lpsa vs lcavol')
abline(recta, col = "red")

confint(recta, level = 0.95)

r1 <- residuals(recta)
sqrt(sum(r1^2) / (dim(datos)[1] - 2)) # RSE


```

# 5

```{r}

library(corrplot)

datos

num_cols <- which(sapply(datos, is.numeric))

corrplot(cor(datos[,num_cols]),type="upper",tl.cex=0.5)

datos.num <- datos[,c(-3,-7,-8)]

rectaMul <- lm(lpsa ~ .,data=datos.num)

summary(rectaMul)

```
#6

```{r}

library(glmnet)


x <- model.matrix(lpsa~.,datos.num)[,-1] #variables numericas

y <- datos.num$lpsa #variable de salida

set.seed(1)

train <- sample(1:nrow(x), nrow(x)/2) #filas de entrenamiento

test <- (-train)


y.test <- y[test]

malla <- 10^seq(10,-2,length=100) #mallado de lambdas

malla.ridge.train <- glmnet(x[train,],y[train],alpha=0,lambda=malla) # regresion ridge sin CV con conjunto de entrenamiento

plot(malla.ridge.train,xvar="lambda" ) # plot de betas vs log(lambda)



cv.out.train <- cv.glmnet(x[train,],y[train],alpha=0)  # regresion ridge con CV con conjunto de entrenamiento

bestlam.train<-cv.out.train$lambda.min  #lambda que minmiza el MSE

bestlam.train

ridge.train<-glmnet(x[train,],y[train],alpha=0, lambda=bestlam.train) #regresion ridge con CV con mejor lambda en conjunto de entrenamiento

coef(ridge.train)[,1]

rectaMul.train <- glmnet(x[train,],y[train],alpha=0, lambda=0)  # regresion multiple con datos de entrenamiento

coef(rectaMul.train)[,1]

#el intercept es mayor en ridge
# beta de lcp mayor en ridge
# los demas betas son menores en ridge

plot(cv.out.train)  #MSE vs log(lambda)

ridge.pred <- predict(ridge.train,newx=x[test,]) # predicion de 'ridge.train' en conjunto de testeo



mean((ridge.pred-y.test)^2) #MSE estimado de Ridge


rectaMul.pred <- predict(rectaMul.train,newx=x[test,])

mean((rectaMul.pred-y.test)^2) #MSE estimado de rectaMul

# El MSE de la regresion multiple de Ridge es menor que la de rectaMul

```

